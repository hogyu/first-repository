{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd031d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a9e5870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 217975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192143</th>\n",
       "      <td>I'm afraid that there isn't any coffee left.</td>\n",
       "      <td>Je crains qu'il ne reste plus de café.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148697</th>\n",
       "      <td>Do you think that you can beat me?</td>\n",
       "      <td>Pensez-vous que vous puissiez me battre ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181353</th>\n",
       "      <td>To tell you the truth, I don't love him.</td>\n",
       "      <td>À la vérité, je ne l'aime pas.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161901</th>\n",
       "      <td>I promise you won't be disappointed.</td>\n",
       "      <td>Je vous promets que vous ne serez pas déçues.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9463</th>\n",
       "      <td>Tom's unarmed.</td>\n",
       "      <td>Tom n’est pas armé.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 eng  \\\n",
       "192143  I'm afraid that there isn't any coffee left.   \n",
       "148697            Do you think that you can beat me?   \n",
       "181353      To tell you the truth, I don't love him.   \n",
       "161901          I promise you won't be disappointed.   \n",
       "9463                                  Tom's unarmed.   \n",
       "\n",
       "                                                  fra  \\\n",
       "192143         Je crains qu'il ne reste plus de café.   \n",
       "148697      Pensez-vous que vous puissiez me battre ?   \n",
       "181353                 À la vérité, je ne l'aime pas.   \n",
       "161901  Je vous promets que vous ne serez pas déçues.   \n",
       "9463                              Tom n’est pas armé.   \n",
       "\n",
       "                                                       cc  \n",
       "192143  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
       "148697  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "181353  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "161901  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "9463    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수:', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f04056a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69200</th>\n",
       "      <td>Don't wear yourself out.</td>\n",
       "      <td>Ne t'épuise pas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66681</th>\n",
       "      <td>Tom won't get involved.</td>\n",
       "      <td>Tom ne sera pas impliqué.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91904</th>\n",
       "      <td>Tom didn't talk about you.</td>\n",
       "      <td>Tom n'a pas parlé de toi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61129</th>\n",
       "      <td>Don't say a word to me.</td>\n",
       "      <td>Ne me dis pas un mot !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86188</th>\n",
       "      <td>He called on me yesterday.</td>\n",
       "      <td>Il m'a rendu visite hier.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              eng                        fra\n",
       "69200    Don't wear yourself out.           Ne t'épuise pas.\n",
       "66681     Tom won't get involved.  Tom ne sera pas impliqué.\n",
       "91904  Tom didn't talk about you.  Tom n'a pas parlé de toi.\n",
       "61129     Don't say a word to me.     Ne me dis pas un mot !\n",
       "86188  He called on me yesterday.  Il m'a rendu visite hier."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b274986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You were there, right?', 'You will stay at home.',\n",
       "       \"You won't be punished.\", ..., 'What time did you wake up?',\n",
       "       'What time did you wake up?', 'What time did you wake up?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e7d1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess_line(line, plus_token = True):\n",
    "    # 소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    # 구두점(Punctuation)을 단어와 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "\n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8f53be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=7000,  \n",
    "        filters=' ',   \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3eedd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "# eng_lines.append(lines.eng.apply(lambda x : preprocess_line(x,plus_token = False)))\n",
    "# fra_lines.append(lines.fra.apply(lambda x : preprocess_line(x),))\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue   \n",
    "        \n",
    "    eng_lines.append(preprocess_line(eng, plus_token = False))\n",
    "    fra_lines.append(preprocess_line(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a18835ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce3065b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 15, 105, 23, 374, 34, 19, 7, 22, 8, 6, 3],\n",
       " [2, 15, 3036, 151, 78, 4, 3],\n",
       " [2, 15, 13, 1135, 8, 3723, 4, 3],\n",
       " [2, 10, 19, 347, 8, 16, 1519, 4, 3],\n",
       " [2, 15, 13, 389, 8, 16, 1519, 4, 3],\n",
       " [2, 10, 19, 1647, 8, 17, 4, 3],\n",
       " [2, 15, 443, 176, 9, 5098, 4, 3],\n",
       " [2, 15, 443, 176, 9, 35, 20, 128, 278, 4, 3],\n",
       " [2, 15, 443, 176, 9, 26, 841, 72, 4, 3],\n",
       " [2, 10, 1136, 176, 9, 10, 841, 72, 4, 3]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c6880be",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "# 시작 토큰 제거\n",
    "decoder_target =[[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "264efb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "#     max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)  \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbbc1659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e01211a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44a675a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5795\n",
      "프랑스어 단어장의 크기 : 8297\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "91088330",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74566131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 10)\n",
      "(30000, 17)\n",
      "(30000, 17)\n",
      "(3000, 10)\n",
      "(3000, 17)\n",
      "(3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcd709ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 512\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
    "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a318870",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dcab64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cc39b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76738696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 512)    2967040     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 512)    4248064     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 512)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masking_3 (Masking)             (None, None, 512)    0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 512), (None, 2099200     masking_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 512),  2099200     masking_3[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 8297)   4256361     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,669,865\n",
      "Trainable params: 15,669,865\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d5dfd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 60s 22ms/step - loss: 1.9338 - val_loss: 1.6347\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 1.4711 - val_loss: 1.4149\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.2786 - val_loss: 1.2803\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.1427 - val_loss: 1.1875\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.0369 - val_loss: 1.1232\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.9560 - val_loss: 1.0834\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.8877 - val_loss: 1.0500\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.8338 - val_loss: 1.0355\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7945 - val_loss: 1.0264\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7665 - val_loss: 1.0248\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7404 - val_loss: 1.0167\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7150 - val_loss: 1.0174\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6940 - val_loss: 1.0094\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.6789 - val_loss: 1.0190\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6699 - val_loss: 1.0263\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6631 - val_loss: 1.0246\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6538 - val_loss: 1.0285\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6466 - val_loss: 1.0280\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6361 - val_loss: 1.0316\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6262 - val_loss: 1.0231\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6133 - val_loss: 1.0266\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6046 - val_loss: 1.0248\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5974 - val_loss: 1.0218\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5829 - val_loss: 1.0145\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.5758 - val_loss: 1.0168\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5752 - val_loss: 1.0209\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5710 - val_loss: 1.0207\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5662 - val_loss: 1.0202\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5610 - val_loss: 1.0163\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5558 - val_loss: 1.0133\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5502 - val_loss: 1.0108\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5452 - val_loss: 1.0108\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5392 - val_loss: 1.0084\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5354 - val_loss: 1.0060\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5290 - val_loss: 1.0063\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5250 - val_loss: 1.0074\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5208 - val_loss: 1.0043\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5154 - val_loss: 1.0075\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5115 - val_loss: 1.0035\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5076 - val_loss: 1.0067\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.5042 - val_loss: 1.0043\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.5008 - val_loss: 1.0085\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4975 - val_loss: 1.0067\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4940 - val_loss: 1.0054\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4918 - val_loss: 1.0082\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4910 - val_loss: 1.0064\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4889 - val_loss: 1.0055\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4878 - val_loss: 1.0076\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4862 - val_loss: 1.0072\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.4866 - val_loss: 1.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3b4d4a670>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], \n",
    "          y=decoder_target_train, \n",
    "          validation_data = ([encoder_input_test, decoder_input_test], \n",
    "                             decoder_target_test),\n",
    "          batch_size=32, \n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4be1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 512)         2967040   \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                [(None, 512), (None, 512) 2099200   \n",
      "=================================================================\n",
      "Total params: 5,066,240\n",
      "Trainable params: 5,066,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6aef271",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "45038413",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e243653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 512)    4248064     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 512),  2099200     embedding_4[0][0]                \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 8297)   4256361     lstm_3[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,603,625\n",
      "Trainable params: 10,603,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d9b5b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd0f184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e83905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32772be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: i want to go right now . \n",
      "정답 문장: je veux y aller tout de suite . \n",
      "번역기가 번역한 문장:  je veux me me maintenan\n",
      "-----------------------------------\n",
      "입력 문장: i m not swallowing that . \n",
      "정답 문장: je ne vais pas avaler a . \n",
      "번역기가 번역한 문장:  je ne je je ne . \n",
      "-----------------------------------\n",
      "입력 문장: i don t want to be alone . \n",
      "정답 문장: je ne veux pas tre seule . \n",
      "번역기가 번역한 문장:  je ne que veux veu\n",
      "-----------------------------------\n",
      "입력 문장: i ate a hot dog for lunch . \n",
      "정답 문장: j ai mang un hot dog au d jeuner . \n",
      "번역기가 번역한 문장:  j j un un un d chie\n",
      "-----------------------------------\n",
      "입력 문장: our tv is out of order . \n",
      "정답 문장: notre t l viseur est hors service . \n",
      "번역기가 번역한 문장:  notre t l l la l\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,201,501,1004,2015]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42774370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
